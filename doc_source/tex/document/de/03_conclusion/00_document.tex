\chapter{Fazit}
\Gls{GAN} bietet einen sehr interessanten Ansatz, um neue Samples auf Basis von originalen Daten zu generieren.
Die Idee, Input-Noise in den originalen Datenraum zu mappen und dies wiederum über zwei (fast) unabhängige
neuronale Netze zu lösen, ist genial. Überzeugend ist vor allem die Tatsache, dass der Generator die originalen Bilder
nie direkt zu Gesicht bekommt. Natürlich stellt sich die Frage, ob dies überhaupt irgendwelche Vorteile mit sich bringt,
jedoch ist es trotzdem beeindruckend, wie gut das Konzept funktioniert.

Ein interessantes Anwendungsgebiet betrifft sicherlich das Machine-Learning selbst. Ein grosses Problem beim Training von
solchen Netzen besteht bei den Daten, da meistens zu wenig vorhanden sind.
Durch Augmentationsmethoden kann das Problem entschärft werden und nun ist in diesem Bereich wieder eine Möglichkeit
dazu gekommen.

Auf jeden Fall ein interessanter Ansatz, den es sich lohnt weiterzuverfolgen.